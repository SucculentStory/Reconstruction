<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<title>Overview</title>

<base target="_blank"/>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
}

pre code {
   display: block; padding: 0.5em;
}

code.r {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<p>% Tutorial 3: Manipulating Data in R<br/>
% R Bootcamp HTML Slides<br/>
% Jared Knowles</p>

<h1>Overview</h1>

<p>In this lesson we hope to learn:</p>

<ul>
<li>Aggregating data</li>
<li>Organizing our data</li>
<li>Manipulating vectors</li>
<li>Dealing with missing data</li>
</ul>

<h1>Again, read in our dataset</h1>

<pre><code class="r"># Set working directory to the tutorial directory In RStudio can do this
# in &#39;Tools&#39; tab
setwd(&quot;~/GitHub/r_tutorial_ed&quot;)
# Load some data
load(&quot;data/smalldata.rda&quot;)
df &lt;- mydat
rm(mydat)
# Note if we don&#39;t assign data to &#39;df&#39; R just prints contents of table
</code></pre>

<h1>Aggregation</h1>

<ul>
<li>Sometimes we need to do some basic checking for the number of observations or types of observations in our dataset</li>
<li>To do this quickly and easily&ndash;the <code>table</code> function is our friend</li>
<li>Let&#39;s look at our observations by year and grade</li>
</ul>

<pre><code class="r">table(df$grade, df$year)
</code></pre>

<pre><code>##    
##     2000 2001 2002
##   3  200  100  200
##   4  100  200  100
##   5  200  100  200
##   6  100  200  100
##   7  200  100  200
##   8  100  200  100
</code></pre>

<ul>
<li>The first command gives the rows, the second gives the columns</li>
</ul>

<h1>Aggregation can be more complex</h1>

<ul>
<li>Let&#39;s aggregate by race and year</li>
</ul>

<pre><code class="r">table(df$year, df$race)
</code></pre>

<pre><code>##       
##          A   B   H   I   W
##   2000  16 370  93   7 414
##   2001  16 370  93   7 414
##   2002  16 370  93   7 414
</code></pre>

<ul>
<li>Race is consistent across years, interesting</li>
<li>What if we want to only look at 3rd graders that year?</li>
</ul>

<h1>More complicated still</h1>

<pre><code class="r">with(df[df$grade == 3, ], {
    table(year, race)
})
</code></pre>

<pre><code>##       race
## year     A   B   H   I   W
##   2000   4  78  22   4  92
##   2001   1  44   8   2  45
##   2002   0  74  20   1 105
</code></pre>

<ul>
<li><code>with</code> specifies a data object to work on, in this case all elements of <code>df</code> where <code>grade==3</code></li>
<li><code>table</code> is the same command as above, but since we specified the data object in the <code>with</code> statement, we don&#39;t need the <code>df$</code> in front of the variables of interest</li>
</ul>

<h1>Quick exercise</h1>

<ul>
<li>Can you find the number of black students in each grade in each year?</li>
<li>hint: <code>with(df[df$___==&quot;B&quot;,]...)</code></li>
<li>How many in year 2002, grade 6?

<ul>
<li>48</li>
</ul></li>
<li>How many in 2001, grade 7?

<ul>
<li>39</li>
</ul></li>
</ul>

<h1>Answer</h1>

<pre><code class="r">with(df[df$race == &quot;B&quot;, ], {
    table(year, grade)
})
</code></pre>

<pre><code>##       grade
## year    3  4  5  6  7  8
##   2000 78 48 87 39 74 44
##   2001 44 78 48 87 39 74
##   2002 74 44 78 48 87 39
</code></pre>

<h1>Tables cont.</h1>

<ul>
<li>This is really powerful for looking at the descriptive dimensions of the data, we can ask questions like:</li>
<li>how many students are at each proficiency level each year?</li>
</ul>

<pre><code class="r">table(df$year, df$proflvl)
</code></pre>

<pre><code>##       
##        advanced basic below basic proficient
##   2000       56   313         143        388
##   2001      229   183          64        424
##   2002      503    27           3        367
</code></pre>

<ul>
<li>how many students are at each proficiency level by race?</li>
</ul>

<pre><code class="r">table(df$race, df$proflvl)
</code></pre>

<pre><code>##    
##     advanced basic below basic proficient
##   A       19     7           3         19
##   B      160   302         162        486
##   H       54    76          33        116
##   I        7     4           1          9
##   W      548   134          11        549
</code></pre>

<h1>Proportional Tables</h1>

<ul>
<li>What if we aren&#39;t interested in counts? </li>
<li>R makes it really easy to calculate proportions</li>
</ul>

<pre><code class="r">prop.table(table(df$race, df$proflvl))
</code></pre>

<pre><code>##    
##      advanced     basic below basic proficient
##   A 0.0070370 0.0025926   0.0011111  0.0070370
##   B 0.0592593 0.1118519   0.0600000  0.1800000
##   H 0.0200000 0.0281481   0.0122222  0.0429630
##   I 0.0025926 0.0014815   0.0003704  0.0033333
##   W 0.2029630 0.0496296   0.0040741  0.2033333
</code></pre>

<ul>
<li>Hmmm, this is goofy. This tells us the proportion of each cell out of the total. Also, the digits are distracting. How can we fix this?</li>
</ul>

<h1>Try number 2</h1>

<pre><code class="r">round(prop.table(table(df$race, df$proflvl), 1), digits = 3)
</code></pre>

<pre><code>##    
##     advanced basic below basic proficient
##   A    0.396 0.146       0.062      0.396
##   B    0.144 0.272       0.146      0.438
##   H    0.194 0.272       0.118      0.416
##   I    0.333 0.190       0.048      0.429
##   W    0.441 0.108       0.009      0.442
</code></pre>

<ul>
<li>The <code>1</code> tells R we want proportions rowise, a <code>2</code> goes columnwise</li>
<li>A few more problems arise&ndash;this pools all observations, including students across years</li>
</ul>

<h1>Aggregating Data</h1>

<ul>
<li>One of the most common questions will be to compute aggregates of data</li>
<li>R has an <code>aggregate</code> function that can be used and helps us avoid the clustering problems above</li>
<li>This works great for simple aggregation like scale score by race, we just need a <code>formula</code> (think I want variable X <strong>by</strong> grouping factor Y) and the statistic we want to compute</li>
</ul>

<pre><code class="r"># Reading Scores by Race
aggregate(readSS ~ race, FUN = mean, data = df)
</code></pre>

<pre><code>##   race readSS
## 1    A  508.7
## 2    B  460.2
## 3    H  473.2
## 4    I  485.2
## 5    W  533.2
</code></pre>

<h1>Aggregate (II)</h1>

<ul>
<li><code>aggregate</code> can take us a little further, we can use aggregate multiple variables at a time</li>
</ul>

<pre><code class="r">aggregate(cbind(readSS, mathSS) ~ race, data = df, mean)
</code></pre>

<pre><code>##   race readSS mathSS
## 1    A  508.7  477.9
## 2    B  460.2  442.5
## 3    H  473.2  442.7
## 4    I  485.2  455.9
## 5    W  533.2  529.8
</code></pre>

<ul>
<li>We can add multiple grouping varialbes using the <code>formula</code> syntax</li>
</ul>

<pre><code class="r">head(aggregate(cbind(readSS, mathSS) ~ race + grade, data = df, mean), 8)
</code></pre>

<pre><code>##   race grade readSS mathSS
## 1    A     3  397.8  454.8
## 2    B     3  409.8  371.6
## 3    H     3  417.7  364.2
## 4    I     3  407.6  449.3
## 5    W     3  481.1  450.7
## 6    A     4  456.0  438.2
## 7    B     4  426.9  408.1
## 8    H     4  418.8  404.6
</code></pre>

<h1>Crosstabs</h1>

<ul>
<li>We can build a systematic cross-tab now</li>
</ul>

<pre><code class="r">ag &lt;- aggregate(readSS ~ race + grade, data = df, mean)
xtabs(readSS ~ ., data = ag)
</code></pre>

<pre><code>##     grade
## race     3     4     5     6     7     8
##    A 397.8 456.0 479.1 539.5 600.4 605.3
##    B 409.8 426.9 447.6 470.9 492.3 523.5
##    H 417.7 418.8 481.2 489.1 500.3 534.2
##    I 407.6 531.1 547.6   0.0 405.5 518.0
##    W 481.1 498.5 517.1 546.6 565.2 596.1
</code></pre>

<ul>
<li>And prettier output</li>
</ul>

<pre><code class="r">ftable(xtabs(readSS ~ ., data = ag))
</code></pre>

<pre><code>##      grade     3     4     5     6     7     8
## race                                          
## A          397.8 456.0 479.1 539.5 600.4 605.3
## B          409.8 426.9 447.6 470.9 492.3 523.5
## H          417.7 418.8 481.2 489.1 500.3 534.2
## I          407.6 531.1 547.6   0.0 405.5 518.0
## W          481.1 498.5 517.1 546.6 565.2 596.1
</code></pre>

<h1>Check your work</h1>

<ul>
<li>What is the mean reading score for 6th grade students with disabilities?

<ul>
<li><strong>481.83</strong></li>
</ul></li>
<li>How many points is this from non-disabled students?

<ul>
<li><strong>29.877</strong></li>
</ul></li>
</ul>

<h1>Answer II</h1>

<pre><code class="r">aggregate(cbind(readSS, mathSS) ~ disab + grade, data = df, mean)
</code></pre>

<pre><code>##    disab grade readSS mathSS
## 1      0     3  449.9  418.3
## 2      1     3  421.1  376.3
## 3      0     4  464.0  454.2
## 4      1     4  438.2  425.1
## 5      0     5  484.9  470.2
## 6      1     5  475.1  431.0
## 7      0     6  511.7  507.9
## 8      1     6  481.8  476.9
## 9      0     7  532.0  532.0
## 10     1     7  516.1  474.3
## 11     0     8  567.6  567.7
## 12     1     8  518.8  534.1
</code></pre>

<h1>Aggregate Isn&#39;t Enough</h1>

<ul>
<li><code>aggregate</code> is cool, but it isn&#39;t very flexible</li>
<li>We can only use aggregate output as a table, which we have to convert to a data frame</li>
<li>There is a better way; the <code>plyr</code> package</li>
<li><code>plyr</code> is a set of routines/logical structure for transforming, summarizing, reshaping, and reorganizing data objects of one type in R into another type</li>
<li>We will focus here on summarizing and aggregating a data frame, but later in the bootcamp we&#39;ll apply functions to lists and turn lists into data frames as well</li>
<li>This is cool!</li>
</ul>

<h1>School Means</h1>

<ul>
<li>Consider the case we want to turn our student level data into school level data</li>
<li>Who hasn&#39;t had to do this?!?</li>
<li>In <code>aggregate</code> we do:</li>
</ul>

<pre><code class="r">z &lt;- aggregate(readSS ~ dist, FUN = mean, data = df)
z
</code></pre>

<pre><code>##   dist readSS
## 1    6  493.8
## 2   15  496.4
## 3   45  492.1
## 4   66  507.2
## 5   75  496.6
## 6  105  491.0
</code></pre>

<ul>
<li>But I want more! I want to aggregate multiple variables. I want to do it across multiple groups. I want the output to be a dataframe I can work on.</li>
<li>Thank you <code>plyr</code></li>
</ul>

<h1>Using plyr</h1>

<ul>
<li><code>plyr</code> has a straightforward syntax</li>
<li>All <code>plyr</code> functions are in the format <strong>XX</strong>ply. The two X&#39;s specify what the input file we are applying a function to is, and then what way we would like it outputted.</li>
<li>In <code>plyr</code> d = dataframe, l= list, m=matrix, and a=array. By far the most common usage is <code>ddply</code></li>
<li>From a dataframe, to a dataframe.</li>
</ul>

<h1>plyr in Action</h1>

<pre><code class="r">library(plyr)
myag &lt;- ddply(df, .(dist, grade), summarize, mean_read = mean(readSS, na.rm = T), 
    mean_math = mean(mathSS, na.rm = T), sd_read = sd(readSS, na.rm = T), sd_math = sd(mathSS, 
        na.rm = T), count_read = length(readSS), count_math = length(mathSS))
head(myag)
</code></pre>

<pre><code>##   dist grade mean_read mean_math sd_read sd_math count_read count_math
## 1    6     3     409.8     425.5   70.82   78.30         50         50
## 2    6     4     471.6     426.2   83.95   68.70        100        100
## 3    6     5     466.2     485.8   75.58   78.00         50         50
## 4    6     6     502.9     476.4   90.29   75.57        100        100
## 5    6     7     536.1     539.9   64.38   76.63         50         50
## 6    6     8     541.6     536.2   66.58   67.05        100        100
</code></pre>

<h1>More plyr</h1>

<ul>
<li>This is great, we can quickly build a summary dataset from individual records</li>
<li>A few advanced tricks. How do we build counts and percentages into our dataset?</li>
</ul>

<pre><code class="r">myag &lt;- ddply(df, .(dist, grade), summarize, mean_read = mean(readSS, na.rm = T), 
    mean_math = mean(mathSS, na.rm = T), sd_read = sd(readSS, na.rm = T), sd_math = sd(mathSS, 
        na.rm = T), count_read = length(readSS), count_math = length(mathSS), 
    count_black = length(race[race == &quot;B&quot;]), per_black = length(race[race == 
        &quot;B&quot;])/length(readSS))
summary(myag[, 7:10])
</code></pre>

<pre><code>##    count_read    count_math   count_black     per_black    
##  Min.   : 50   Min.   : 50   Min.   :15.0   Min.   :0.300  
##  1st Qu.: 50   1st Qu.: 50   1st Qu.:20.8   1st Qu.:0.378  
##  Median : 75   Median : 75   Median :30.0   Median :0.400  
##  Mean   : 75   Mean   : 75   Mean   :30.8   Mean   :0.411  
##  3rd Qu.:100   3rd Qu.:100   3rd Qu.:40.0   3rd Qu.:0.453  
##  Max.   :100   Max.   :100   Max.   :48.0   Max.   :0.480  
</code></pre>

<h1>Quick Check</h1>

<ul>
<li>What if we want to compare how districts do on educating ELL students?</li>
<li>What district ID has the highest mean score for 4th grade ELL students on reading? Math?

<ul>
<li>66 in reading, 105 in math</li>
</ul></li>
<li>How many students are in these classes?

<ul>
<li>12 and 7 respectively</li>
</ul></li>
</ul>

<h1>Answer III</h1>

<pre><code class="r">myag2 &lt;- ddply(df, .(dist, grade, ell), summarize, mean_read = mean(readSS, 
    na.rm = T), mean_math = mean(mathSS, na.rm = T), sd_read = sd(readSS, na.rm = T), 
    sd_math = sd(mathSS, na.rm = T), count_read = length(readSS), count_math = length(mathSS), 
    count_black = length(race[race == &quot;B&quot;]), per_black = length(race[race == 
        &quot;B&quot;])/length(readSS))
subset(myag2, ell == 1 &amp; grade == 4)
</code></pre>

<pre><code>##    dist grade ell mean_read mean_math sd_read sd_math count_read
## 4     6     4   1     424.6     375.8   76.98   41.74         17
## 16   15     4   1     425.4     420.6   84.18   18.74          6
## 28   45     4   1     405.5     422.8   93.56   89.99          6
## 40   66     4   1     469.4     407.0   78.71   63.82         12
## 52   75     4   1     389.6     376.3   49.68   39.15         10
## 64  105     4   1     411.6     439.8   68.48   55.78          7
##    count_math count_black per_black
## 4          17           3    0.1765
## 16          6           0    0.0000
## 28          6           0    0.0000
## 40         12           3    0.2500
## 52         10           2    0.2000
## 64          7           1    0.1429
</code></pre>

<h1>Sorting</h1>

<ul>
<li>A key way to explore data in tabular form is to sort data</li>
<li>Sorting data in R can be dangerous as you can reorder the vectors of a dataframe</li>
<li>We use the <code>order</code> function to sort data</li>
</ul>

<pre><code class="r">df.badsort &lt;- order(df$readSS, df$mathSS)
head(df.badsort)
</code></pre>

<pre><code>## [1]  106 1026    2   56  122  118
</code></pre>

<ul>
<li>Why is this wrong?</li>
<li>What is R giving us?</li>
<li>Rownames&hellip;</li>
</ul>

<h1>Correct Example</h1>

<ul>
<li>To fix it, we need to tell R to reorder the rownames in the order we want</li>
</ul>

<pre><code class="r">df.sort &lt;- df[order(df$readSS, df$mathSS, df$attday), ]
head(df[, c(3, 23, 29, 30)])
</code></pre>

<pre><code>##    stuid attday readSS mathSS
## 1 149995    180  357.3  387.3
## 2  13495    180  263.9  302.6
## 3 106495    160  369.7  365.5
## 4  45205    168  346.6  344.5
## 5 142705    156  373.1  441.2
## 6  14995    157  436.8  463.4
</code></pre>

<pre><code class="r">head(df.sort[, c(3, 23, 29, 30)])
</code></pre>

<pre><code>##       stuid attday readSS mathSS
## 106  106705    160  251.5  277.0
## 1026  80995    176  263.2  377.8
## 2     13495    180  263.9  302.6
## 56   122402    180  264.3  271.7
## 122   79705    168  266.4  318.7
## 118   40495    173  266.9  275.0
</code></pre>

<h1>Let&#39;s clean it up a bit more</h1>

<pre><code class="r">head(df[with(df, order(-readSS, -attday)), c(3, 23, 29, 30)])
</code></pre>

<pre><code>##       stuid attday readSS mathSS
## 1631 145205    137  833.2  828.4
## 1462 107705    180  773.3  746.6
## 2252 122902    180  744.0  621.6
## 2341  44902    175  741.7  676.3
## 1482 134705    180  739.2  705.4
## 1630  14495    162  738.9  758.2
</code></pre>

<ul>
<li>Here we find the high performing students, note that the <code>-</code> denotes we want descending order, R&#39;s default is ascending order</li>
<li>This is easy to correct</li>
</ul>

<h1>About sorting</h1>

<ul>
<li>Sorting works differently on some data types, matrices are slightly different</li>
</ul>

<pre><code class="r">M &lt;- matrix(c(1, 2, 2, 2, 3, 6, 4, 5), 4, 2, byrow = FALSE, dimnames = list(NULL, 
    c(&quot;a&quot;, &quot;b&quot;)))
M[order(M[, &quot;a&quot;], -M[, &quot;b&quot;]), ]
</code></pre>

<pre><code>##      a b
## [1,] 1 3
## [2,] 2 6
## [3,] 2 5
## [4,] 2 4
</code></pre>

<ul>
<li>Tables are familiar</li>
</ul>

<pre><code class="r">mytab &lt;- table(df$grade, df$year)
mytab[order(mytab[, 1]), ]
</code></pre>

<pre><code>##    
##     2000 2001 2002
##   4  100  200  100
##   6  100  200  100
##   8  100  200  100
##   3  200  100  200
##   5  200  100  200
##   7  200  100  200
</code></pre>

<pre><code class="r">mytab[order(mytab[, 2]), ]
</code></pre>

<pre><code>##    
##     2000 2001 2002
##   3  200  100  200
##   5  200  100  200
##   7  200  100  200
##   4  100  200  100
##   6  100  200  100
##   8  100  200  100
</code></pre>

<h1>Filtering Data</h1>

<ul>
<li>Filtering data is an incredibly powerful feature and we have already seen it used to do some interesting things</li>
<li>Filtering data in R is loaded with trouble though, because the filtering arguments must be very carefully specified</li>
<li>Filtering is like a mini-sort</li>
<li>Always, always, always check your work</li>
<li>And remember, this is the place the NAs do the most damage</li>
<li>Let&#39;s look at some examples</li>
</ul>

<h1>Basic Filtering a Column</h1>

<pre><code class="r"># Gives all rows that meet this requirement
df[df$readSS &gt; 800, ]
</code></pre>

<pre><code>##            X school  stuid grade schid dist white black hisp indian asian
## 1631 1281061    852 145205     8   205   15     1     0    0      0     0
##      econ female ell disab sch_fay dist_fay luck ability measerr teachq
## 1631    0      1   0     0       0        0    0   108.3   6.325  155.7
##      year attday schoolscore district schoolhigh schoolavg schoollow
## 1631 2001    137       227.7       19          0         1         0
##      readSS mathSS  proflvl race
## 1631  833.2  828.4 advanced    W
</code></pre>

<pre><code class="r">df$grade[df$mathSS &gt; 800]
</code></pre>

<pre><code>## [1] 8
</code></pre>

<pre><code class="r"># Gives all values of grade that meet this requirement
</code></pre>

<ul>
<li>This seems basic enough, let&#39;s filter on multiple dimensions</li>
<li>Before the brackets we specify what we want returned, and within the brackets we present the logical expression to evaluate</li>
<li>Behind the scenes R does a logical test and gets the row numbers that match the logical expression</li>
<li>It then combines them back with the object in front of the brackets to return the values</li>
<li>So great we don&#39;t have to do that!</li>
</ul>

<h1>Multiple filters</h1>

<pre><code class="r">df$grade[df$black == 1 &amp; df$readSS &gt; 650]
</code></pre>

<pre><code>##  [1] 8 7 8 6 6 7 8 7 8 8 8 4
</code></pre>

<ul>
<li>What happens if we type <code>df$black=1</code> or <code>black==1</code>? </li>
<li>Why won&#39;t this work?</li>
</ul>

<h1>Using filters to assign values</h1>

<ul>
<li>We can also use filters to assign values as well</li>
<li>This is how you recode variables and create new ones</li>
<li>Let&#39;s create a variable <code>spread</code> indicating whether a district has high or low spread among its student scores</li>
</ul>

<pre><code class="r">myag$spread &lt;- NA  # create variable
myag$spread[myag$sd_read &lt; 75] &lt;- &quot;low&quot;
myag$spread[myag$sd_read &gt; 75] &lt;- &quot;high&quot;
myag$spread &lt;- as.factor(myag$spread)
summary(myag$spread)
</code></pre>

<pre><code>## high  low 
##   26   10 
</code></pre>

<h1>Check your work</h1>

<ul>
<li>The previous block of code is a useful way to learn how to recode variables</li>
</ul>

<pre><code class="r">myag$spread &lt;- NA  # create variable
myag$spread[myag$sd_read &lt; 75] &lt;- &quot;low&quot;
myag$spread[myag$sd_read &gt; 75] &lt;- &quot;high&quot;
myag$spread &lt;- as.factor(myag$spread)
</code></pre>

<ul>
<li>Create a new variable in <code>myag</code> called <code>schoolperf</code> for <code>mean_math</code> scores with the following coding scheme:</li>
</ul>

<table><thead>
<tr>
<th>Grade</th>
<th>Score Range</th>
<th>Code</th>
</tr>
</thead><tbody>
<tr>
<td>3</td>
<td>&gt;425</td>
<td>&ldquo;Hi&rdquo;</td>
</tr>
<tr>
<td>4</td>
<td>&gt;450</td>
<td>&ldquo;Hi&rdquo;</td>
</tr>
<tr>
<td>5</td>
<td>&gt;475</td>
<td>&ldquo;Hi&rdquo;</td>
</tr>
<tr>
<td>6</td>
<td>&gt;500</td>
<td>&ldquo;Hi&rdquo;</td>
</tr>
<tr>
<td>7</td>
<td>&gt;525</td>
<td>&ldquo;Hi&rdquo;</td>
</tr>
<tr>
<td>8</td>
<td>&gt;575</td>
<td>&ldquo;Hi&rdquo;</td>
</tr>
</tbody></table>

<ul>
<li>All other values are coded as &ldquo;lo&rdquo;</li>
<li>How many &ldquo;hi&rdquo; and &ldquo;lo&rdquo; observations do we have?</li>
<li>By <code>dist</code>?</li>
</ul>

<h1>Results</h1>

<pre><code class="r">myag$schoolperf &lt;- &quot;lo&quot;
myag$schoolperf[myag$grade == 3 &amp; myag$mean_math &gt; 425] &lt;- &quot;hi&quot;
myag$schoolperf[myag$grade == 4 &amp; myag$mean_math &gt; 450] &lt;- &quot;hi&quot;
myag$schoolperf[myag$grade == 5 &amp; myag$mean_math &gt; 475] &lt;- &quot;hi&quot;
myag$schoolperf[myag$grade == 6 &amp; myag$mean_math &gt; 500] &lt;- &quot;hi&quot;
myag$schoolperf[myag$grade == 7 &amp; myag$mean_math &gt; 525] &lt;- &quot;hi&quot;
myag$schoolperf[myag$grade == 8 &amp; myag$mean_math &gt; 575] &lt;- &quot;hi&quot;
myag$schoolperf &lt;- as.factor(myag$schoolperf)
summary(myag$schoolperf)
</code></pre>

<pre><code>## hi lo 
## 18 18 
</code></pre>

<pre><code class="r">table(myag$dist, myag$schoolperf)
</code></pre>

<pre><code>##      
##       hi lo
##   6    3  3
##   15   3  3
##   45   3  3
##   66   3  3
##   75   3  3
##   105  3  3
</code></pre>

<h1>Let&#39;s replace data</h1>

<ul>
<li>For district 6 let&#39;s negate the grade 3 scores by replacing them with missing data</li>
</ul>

<pre><code class="r">myag$mean_read[myag$dist == 6 &amp; myag$grade == 3] &lt;- NA
head(myag[, 1:4], 2)
</code></pre>

<pre><code>##   dist grade mean_read mean_math
## 1    6     3        NA     425.5
## 2    6     4     471.6     426.2
</code></pre>

<ul>
<li>Let&#39;s replace one data element with another</li>
</ul>

<pre><code class="r">myag$mean_read[myag$dist == 6 &amp; myag$grade == 3] &lt;- myag$mean_read[myag$dist == 
    6 &amp; myag$grade == 4]
head(myag[, 1:4], 2)
</code></pre>

<pre><code>##   dist grade mean_read mean_math
## 1    6     3     471.6     425.5
## 2    6     4     471.6     426.2
</code></pre>

<ul>
<li>Voila</li>
</ul>

<h1>Why do NAs matter so much?</h1>

<ul>
<li>Let&#39;s consider the case above but insert some NA values for all 3rd grade tests</li>
</ul>

<pre><code class="r">myag$mean_read[myag$grade == 3] &lt;- NA
head(myag[order(myag$grade), 1:4])
</code></pre>

<pre><code>##    dist grade mean_read mean_math
## 1     6     3        NA     425.5
## 7    15     3        NA     403.8
## 13   45     3        NA     404.9
## 19   66     3        NA     438.3
## 25   75     3        NA     408.4
## 31  105     3        NA     406.1
</code></pre>

<h1>NAs II</h1>

<ul>
<li>Now let&#39;s calculate a few statistics:</li>
</ul>

<pre><code class="r">mean(myag$mean_math)
</code></pre>

<pre><code>## [1] 490.7
</code></pre>

<pre><code class="r">mean(myag$mean_read)
</code></pre>

<pre><code>## [1] NA
</code></pre>

<ul>
<li>Remember, NA values propogate, so R assumes an NA value could take literally any value, and as such it is impossible to know the <code>mean</code> of a vector with NA</li>
<li>We can override this though:</li>
</ul>

<pre><code class="r">mean(myag$mean_math, na.rm = T)
</code></pre>

<pre><code>## [1] 490.7
</code></pre>

<pre><code class="r">mean(myag$mean_read, na.rm = T)
</code></pre>

<pre><code>## [1] 507.5
</code></pre>

<h1>Beyond the Mean</h1>

<ul>
<li>But for other problems it is tricky</li>
<li>What if we want to know the number of rows that have a <code>mean_read</code> of less than 500?</li>
</ul>

<pre><code class="r">length(myag$dist[myag$mean_read &lt; 500])
</code></pre>

<pre><code>## [1] 20
</code></pre>

<pre><code class="r">head(myag$mean_read[myag$mean_read &lt; 500])
</code></pre>

<pre><code>## [1]    NA 471.6 466.2    NA 436.1 490.9
</code></pre>

<ul>
<li>And what if we want to add the standard deviation to these vectors?</li>
</ul>

<pre><code class="r">badvar &lt;- myag$mean_read + myag$sd_read
summary(badvar)
</code></pre>

<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##     505     566     589     587     612     658       6 
</code></pre>

<h1>So we need to filter NAs explicitly</h1>

<ul>
<li>Consider the case where two sets of variables have different missing elements</li>
</ul>

<pre><code class="r">myag$sd_read[myag$count_read &lt; 100 &amp; myag$mean_read &lt; 550] &lt;- NA
length(myag$mean_read[myag$mean_read &lt; 550])
</code></pre>

<pre><code>## [1] 30
</code></pre>

<pre><code class="r">length(myag$mean_read[myag$mean_read &lt; 550 &amp; !is.na(myag$mean_read)])
</code></pre>

<pre><code>## [1] 24
</code></pre>

<ul>
<li>What is <code>!is.na()</code> ?

<ul>
<li><code>is.na()</code> is a helpful function to identify TRUE if a value is missing</li>
<li><code>!</code> is the reverse operator</li>
<li>We are asking R if this value is not a missing value, and to only give us non-missing values back</li>
</ul></li>
</ul>

<h1>Merging Data</h1>

<ul>
<li>It is unlikely all the data we will want resides in a single dataset and often we have to combine data from several sources</li>
<li>R makes this easy, but that simplicity comes at a cost&ndash;it can be easy to make mistakes if you don&#39;t specify things carefully</li>
</ul>

<h1>Reshaping Data</h1>

<ul>
<li>Reshaping data is a slightly different issue than aggregating data</li>
<li>Let&#39;s review the two data types: long and wide</li>
</ul>

<pre><code class="r">head(df[, 1:10], 3)
</code></pre>

<pre><code>##     X school  stuid grade schid dist white black hisp indian
## 1  44      1 149995     3   495  105     0     1    0      0
## 2  53      1  13495     3   495   45     0     1    0      0
## 3 116      1 106495     3   495   45     0     1    0      0
</code></pre>

<ul>
<li>Now let&#39;s look at wide:</li>
</ul>

<pre><code class="r">head(widedf[, 28:40], 3)
</code></pre>

<pre><code>##   readSS.2000 mathSS.2000 proflvl.2000 race.2000  X.2001 school.2001
## 1       357.3       387.3        basic         B  441000           1
## 2       263.9       302.6  below basic         B  531000           1
## 3       369.7       365.5        basic         B 1161000           1
##   grade.2001 schid.2001 dist.2001 white.2001 black.2001 hisp.2001
## 1          4        495       105          0          1         0
## 2          4        495        45          0          1         0
## 3          4        495        45          0          1         0
##   indian.2001
## 1           0
## 2           0
## 3           0
</code></pre>

<ul>
<li>How did we do this?</li>
</ul>

<h1>Wide data v. Long Data</h1>

<ul>
<li>The great debate</li>
<li>Most econometrics, panel, and time series datasets come wide and so these seem familiar</li>
<li>R for most cases prefers long data, including for most graphing and analysis functions</li>
<li>But, not all</li>
<li>So we have to learn both</li>
</ul>

<h1>The reshape Function</h1>

<ul>
<li><code>reshape</code> is the way to move from wide to long</li>
<li>The data stays the same, but the shape of it changes</li>
<li>The long data had dimensions: <code>2700, 32</code></li>
<li>The wide data has dimensions: <code>1200, 91</code></li>
<li>How do we get to these numbers?

<ul>
<li>The rows in the wide dataframe represent unique students</li>
</ul></li>
</ul>

<h1>Deconstructing reshape</h1>

<pre><code class="r">widedf &lt;- reshape(df, timevar = &quot;year&quot;, idvar = &quot;stuid&quot;, direction = &quot;wide&quot;)
</code></pre>

<ul>
<li><code>idvar</code> represents the unit we want to represent a single row, in this case each unique student gets a single row</li>
<li>In this simple case <code>timevar</code> is the variable that differenaties between two rows with the same student ID</li>
<li><code>direction</code> tells R we are going to move to wide data</li>
<li>As written all data will move, but using the <code>varying</code> argument we can tell R explicitly which items we want to move wide</li>
</ul>

<h1>What about Wide to Long?</h1>

<ul>
<li>We often need to do this to plot data in R</li>
<li>Luckily the <code>reshape</code> function works well in both directions</li>
</ul>

<pre><code class="r">longdf &lt;- reshape(widedf, idvar = &quot;stuid&quot;, timevar = &quot;year&quot;, varying = names(widedf[, 
    2:91]), direction = &quot;long&quot;, sep = &quot;.&quot;)
</code></pre>

<ul>
<li>If our data is formatted nicely, R can do the guessing and identify the years for us by parsing the dataframe names</li>
</ul>

<h1>Subsetting Data</h1>

<ul>
<li>We have already seen a lot of subsetting examples above, which is what filtering is, but R provides some great shortcuts to this</li>
<li>Let&#39;s look at the <code>subset</code> function to get only 4th grade scores</li>
</ul>

<pre><code class="r">g4 &lt;- subset(df, grade == 4)
dim(g4)
</code></pre>

<pre><code>## [1] 400  32
</code></pre>

<ul>
<li>This is equivalent to:</li>
</ul>

<pre><code class="r">g4_b &lt;- df[df$grade == 4, ]
</code></pre>

<ul>
<li>These two elements are the same:</li>
</ul>

<pre><code class="r">identical(g4, g4_b)
</code></pre>

<pre><code>## [1] TRUE
</code></pre>

<h1>That&#39;s it</h1>

<ul>
<li>Now you can filter, subset, sort, recode, and aggregate data!</li>
<li>Let&#39;s look at a few exercises to test these skills</li>
<li>Once these skills are mastered, we can begin to understand how to automate R to clean data with known errors, and to recode data in R so it is ready to be used for analysis</li>
<li>Then we can really take off!</li>
</ul>

<h1>Exercises</h1>

<ol>
<li>Sort <code>df</code> on <code>measerr</code> and <code>mathss</code>. What are the highest 5 values of each. </li>
</ol>

<h1>Other References</h1>

<ul>
<li><a href="https://github.com/hadley/devtools/wiki/vocabulary">An R Vocabulary for Starting Out</a></li>
<li><a href="http://www.statmethods.net/management/index.html">Quick-R: Data Management</a></li>
<li><a href="http://www.ats.ucla.edu/stat/r/faq/default.htm">UCLA ATS: R FAQ on Data Management</a></li>
<li><a href="http://www.twotorials.com/">Video Tutorials</a></li>
</ul>

</body>

</html>

